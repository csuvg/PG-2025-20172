{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5d510ca",
   "metadata": {},
   "source": [
    "## Ingeniería de características"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adf56acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import re\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b5fc01d",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './dataset/violenciaIntrafamiliarGuatemala2008_2023_v2.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./dataset/violenciaIntrafamiliarGuatemala2008_2023_v2.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\diego\\Downloads\\UVG\\CODING\\Semestre9\\Tesis\\Tesis\\ViolenciaIntrafamiliar\\.venv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\diego\\Downloads\\UVG\\CODING\\Semestre9\\Tesis\\Tesis\\ViolenciaIntrafamiliar\\.venv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\diego\\Downloads\\UVG\\CODING\\Semestre9\\Tesis\\Tesis\\ViolenciaIntrafamiliar\\.venv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\diego\\Downloads\\UVG\\CODING\\Semestre9\\Tesis\\Tesis\\ViolenciaIntrafamiliar\\.venv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\diego\\Downloads\\UVG\\CODING\\Semestre9\\Tesis\\Tesis\\ViolenciaIntrafamiliar\\.venv\\lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './dataset/violenciaIntrafamiliarGuatemala2008_2023_v2.csv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"./dataset/violenciaIntrafamiliarGuatemala2008_2023_v2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08af778b",
   "metadata": {},
   "source": [
    "## Dropear columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2406ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop([\n",
    "    'VIC_OCUP_INE', 'AGR_OCUP_INE', 'VIC_OCUP_GRUPO',\n",
    "       'VIC_OCUP_SUB_GRUPO_PRINCIPAL', 'VIC_OCUP_SUB_GRUPO',\n",
    "       'VIC_OCUP_GRUPO_UNITARIO', 'AGR_OCUP_GRUPO',\n",
    "       'AGR_OCUP_SUB_GRUPO_PRINCIPAL', 'AGR_OCUP_SUB_GRUPO',\n",
    "       'AGR_OCUP_GRUPO_UNITARIO',\n",
    "       'VIC_DEDICA', 'AGR_DEDICA', 'AGR_OCUP', 'VIC_OCUP'\n",
    "    \n",
    "    ],\n",
    "        axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e56833",
   "metadata": {},
   "source": [
    "### Disminuir la variable de HIJOS a rangos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93086f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rangos_hijos(num):\n",
    "    if num == 0:\n",
    "        return \"sin hijos\"\n",
    "    elif num == 1:\n",
    "        return \"hijo unico\"\n",
    "    elif 1<num <4:\n",
    "        return \"hijos medios\"\n",
    "    elif 3<num:\n",
    "        return \"muchos hijos\"\n",
    "    elif num==9999.0:\n",
    "        return \"ignorado\"\n",
    "df[\"CANTIDAD_HIJOS\"] = df[\"TOTAL_HIJOS\"].apply(lambda x: rangos_hijos(x))\n",
    "def con_tipo_hijos(x):\n",
    "    if x == 0:\n",
    "        return \"si\"\n",
    "    elif x == 9999.0:\n",
    "        return \"ignorado\"\n",
    "    else:\n",
    "        return \"no\"\n",
    "df[\"CON_HIJ_HOM\"] = df[\"NUM_HIJ_HOM\"].apply(lambda x: con_tipo_hijos(x))\n",
    "df[\"CON_HIJ_MUJ\"] = df[\"NUM_HIJ_MUJ\"].apply(lambda x: con_tipo_hijos(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056eec0b",
   "metadata": {},
   "source": [
    "### Disminuir la variable de EDAD a rangos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c5c71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rango_edad(num):\n",
    "    if num <= 13:\n",
    "        return \"ninio\"\n",
    "    elif num <= 18:\n",
    "        return \"adolescente\"\n",
    "    elif num <= 40:\n",
    "        return \"adulto joven\"\n",
    "    elif num <= 60:\n",
    "        return \"adulto medio\"\n",
    "    elif num == 9999.0:\n",
    "        return \"ignorado\"\n",
    "    else:\n",
    "        return \"adulto mayor\"\n",
    "df[\"VIC_RANGO_EDAD\"] = df[\"VIC_EDAD\"].apply(lambda x: rango_edad(x))\n",
    "df[\"AGR_RANGO_EDAD\"] = df[\"AGR_EDAD\"].apply(lambda x: rango_edad(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db27676e",
   "metadata": {},
   "source": [
    "### Disminuir la variable de ESCOLARIDAD a nivel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b4d7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nivel_escolaridad(nivel):\n",
    "    if re.search(\"basico\", nivel):\n",
    "        return \"basicos\"\n",
    "    elif re.search(\"primaria\", nivel):\n",
    "        return \"primaria\"\n",
    "    elif re.search(\"universitario\", nivel):\n",
    "        return \"nivel_medio_o_superior\"\n",
    "    elif re.search(\"(diversificado|divesificado)\", nivel):\n",
    "        return \"nivel_medio_o_superior\"\n",
    "    return nivel\n",
    "df[\"VIC_NIV_ESCOLARIDAD\"] = df[\"VIC_ESCOLARIDAD\"].apply(lambda x: nivel_escolaridad(x))\n",
    "df[\"AGR_NIV_ESCOLARIDAD\"] = df[\"AGR_ESCOLARIDAD\"].apply(lambda x: nivel_escolaridad(x))\n",
    "df[\"VIC_ESCOLARIDAD\"] = df[\"VIC_ESCOLARIDAD\"].apply(lambda x: nivel_escolaridad(x))\n",
    "df[\"AGR_ESCOLARIDAD\"] = df[\"AGR_ESCOLARIDAD\"].apply(lambda x: nivel_escolaridad(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df96e68",
   "metadata": {},
   "source": [
    "### Disminuir la variable NUMERO_DE_OTROS_AGRESORES a rangos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f87c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rango_otros_agresores(num):\n",
    "    if num == 0:\n",
    "        return \"no\"\n",
    "    elif num == 99:\n",
    "        return \"ignorado\"\n",
    "    else:\n",
    "        return \"si\"\n",
    "\n",
    "df[\"OTROS_AGRESORES\"] = df[\"AGRESORES_OTROS_TOTAL\"].apply(lambda x: rango_otros_agresores(x))\n",
    "df[\"OTROS_AGRESORES_N_AS\"] = df[\"AGR_OTRAS_N_AS\"].apply(lambda x: rango_otros_agresores(x))\n",
    "df[\"OTROS_AGRESORES_N_OS\"] = df[\"AGR_OTROS_N_OS\"].apply(lambda x: rango_otros_agresores(x))\n",
    "df[\"OTROS_AGRESORES_MUJ\"] = df[\"AGR_OTRAS_MUJ\"].apply(lambda x: rango_otros_agresores(x))\n",
    "df[\"OTROS_AGRESORES_HOM\"] = df[\"AGR_OTROS_HOM\"].apply(lambda x: rango_otros_agresores(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfdeb3a9",
   "metadata": {},
   "source": [
    "### Disminuir la variable de OTRAS_VICTIMAS a rangos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8efb395a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rango_otras_victimas(num):\n",
    "    if num == 0:\n",
    "        return \"no\"\n",
    "    elif num == 9999.0:\n",
    "        return \"ignorado\"\n",
    "    else:\n",
    "        return \"si\"\n",
    "\n",
    "df[\"VIC_OTRAS_VICTIMAS\"] = df[\"OTRAS_VICTIMAS\"].apply(lambda x: rango_otras_victimas(x))\n",
    "df[\"VIC_OTRAS_VICTIMAS_HOM\"] = df[\"VIC_OTRAS_HOM\"].apply(lambda x: rango_otras_victimas(x))\n",
    "df[\"VIC_OTRAS_VICTIMAS_MUJ\"] = df[\"VIC_OTRAS_MUJ\"].apply(lambda x: rango_otras_victimas(x))\n",
    "df[\"VIC_OTRAS_VICTIMAS_N_OS\"] = df[\"VIC_OTRAS_N_OS\"].apply(lambda x: rango_otras_victimas(x))\n",
    "df[\"VIC_OTRAS_VICTIMAS_N_AS\"] = df[\"VIC_OTRAS_N_AS\"].apply(lambda x: rango_otras_victimas(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dfdaa2e",
   "metadata": {},
   "source": [
    "### Construir una variable para determinar los casos de violencia donde el tipo sea físico, psicológico, patrimonial o sexual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68ab989",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear nuevas columnas booleanas\n",
    "df[\"VIOLENCIA_FISICA\"] = df[\"HEC_TIPAGRE\"].str.contains(\"fisica\").astype(str).replace({\"True\":\"presente\", \"False\":\"no presente\"})\n",
    "df[\"VIOLENCIA_PSICOLOGICA\"] = df[\"HEC_TIPAGRE\"].str.contains(\"psicologica\").astype(str).replace({\"True\":\"presente\", \"False\":\"no presente\"})\n",
    "df[\"VIOLENCIA_SEXUAL\"] = df[\"HEC_TIPAGRE\"].str.contains(\"sexual\").astype(str).replace({\"True\":\"presente\", \"False\":\"no presente\"})\n",
    "df[\"VIOLENCIA_PATRIMONIAL\"] = df[\"HEC_TIPAGRE\"].str.contains(\"patrimonial\").astype(str).replace({\"True\":\"presente\", \"False\":\"no presente\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05905c15",
   "metadata": {},
   "source": [
    "### Construir una variable para establecer la diferencia de edad entre la víctima y el agresor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7473a5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_age_difference(row):\n",
    "    if row[\"AGR_EDAD\"] >=9999 or row[\"VIC_EDAD\"] >=9999:\n",
    "        return 9999\n",
    "    return abs(row[\"AGR_EDAD\"] - row[\"VIC_EDAD\"])\n",
    "    \n",
    "def get_who_is_bigger(row):\n",
    "    if row[\"AGR_EDAD\"] >=9999 or row[\"VIC_EDAD\"] >=9999:\n",
    "        return \"ignorado\"\n",
    "    elif row[\"AGR_EDAD\"] > row[\"VIC_EDAD\"]:\n",
    "        return \"agresor\"\n",
    "    elif row[\"AGR_EDAD\"] < row[\"VIC_EDAD\"]:\n",
    "        return \"victima\"\n",
    "    else:\n",
    "        return \"iguales\"\n",
    "    \n",
    "df[\"DIF_EDAD_VIC_AGR\"] = df.apply(get_age_difference, axis=1)\n",
    "df[\"QUIEN_ES_MAYOR\"] = df.apply(get_who_is_bigger, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8503fae9",
   "metadata": {},
   "source": [
    "### Construir una variable que muestre la diferencia de alfabetizacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b516bca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_difference_alfab(row):\n",
    "    if row[\"AGR_ALFAB\"] == \"ignorado\" or row[\"VIC_ALFAB\"] == \"ignorado\":\n",
    "        return \"ignorado\"\n",
    "    elif row[\"AGR_ALFAB\"] == row[\"VIC_ALFAB\"]:\n",
    "        return \"iguales\"\n",
    "    elif row[\"AGR_ALFAB\"] == \"alfabeta\":\n",
    "        return \"agresor\"\n",
    "    elif row[\"VIC_ALFAB\"] == \"alfabeta\":\n",
    "        return \"victima\"\n",
    "\n",
    "df[\"DIF_ALFAB\"] = df.apply(get_difference_alfab, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47cdd447",
   "metadata": {},
   "source": [
    "### Construir una variable que muestre la diferencia de la fecha del registro de la agresion contra la fecha cuando sucedio la agresion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b818b6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapeo de meses en español a números\n",
    "MESES_MAP = {\n",
    "    \"enero\": 1,\n",
    "    \"febrero\": 2,\n",
    "    \"marzo\": 3,\n",
    "    \"abril\": 4,\n",
    "    \"mayo\": 5,\n",
    "    \"junio\": 6,\n",
    "    \"julio\": 7,\n",
    "    \"agosto\": 8,\n",
    "    \"septiembre\": 9,\n",
    "    \"octubre\": 10,\n",
    "    \"noviembre\": 11,\n",
    "    \"diciembre\": 12\n",
    "}\n",
    "\n",
    "def get_difference_dates_registro_hec(row):\n",
    "    hec_ano = row[\"HEC_ANO\"]\n",
    "    hec_mes = row[\"HEC_MES\"]\n",
    "    hec_dia = row[\"HEC_DIA\"]\n",
    "\n",
    "    if hec_ano == 9999:\n",
    "        return \"ignorado\"\n",
    "\n",
    "    try:\n",
    "        mes_emision = MESES_MAP.get(row[\"MES_EMISION\"].lower())\n",
    "        fecha_emision = datetime(int(row[\"ANO_EMISION\"]), mes_emision, int(row[\"DIA_EMISION\"]))\n",
    "    except Exception as e:\n",
    "        return \"fecha emisión inválida\"\n",
    "\n",
    "    # Si el mes es ignorado\n",
    "    if hec_mes == \"ignorado\":\n",
    "        if hec_ano != row[\"ANO_EMISION\"]:\n",
    "            diff_years = row[\"ANO_EMISION\"] - hec_ano\n",
    "            if diff_years < 0:\n",
    "                return \"fecha futura\"\n",
    "            elif diff_years == 0:\n",
    "                return \"ignorado\"\n",
    "            elif diff_years == 1:\n",
    "                return \"1 año\"\n",
    "            elif diff_years <= 5:\n",
    "                return \"5 años\"\n",
    "            elif diff_years <= 10:\n",
    "                return \"10 años\"\n",
    "            else:\n",
    "                return \"más de 10 años\"\n",
    "        else:\n",
    "            return \"ignorado\"\n",
    "\n",
    "    mes_hecho = MESES_MAP.get(hec_mes.lower())\n",
    "    if mes_hecho is None:\n",
    "        return \"mes inválido\"\n",
    "\n",
    "    # Si el día es desconocido, aproximar usando meses\n",
    "    if hec_dia == 99:\n",
    "        diff_months = (fecha_emision.year - hec_ano) * 12 + (fecha_emision.month - mes_hecho)\n",
    "        diff_days = diff_months * 30\n",
    "    else:\n",
    "        try:\n",
    "            fecha_hecho = datetime(int(hec_ano), mes_hecho, int(hec_dia))\n",
    "            diff_days = (fecha_emision - fecha_hecho).days\n",
    "        except Exception:\n",
    "            return \"fecha hecho inválida\"\n",
    "\n",
    "    # Clasificación según diferencia en días\n",
    "    if diff_days < 0:\n",
    "        return \"fecha futura\"\n",
    "    elif diff_days <= 7:\n",
    "        return \"una semana\"\n",
    "    elif diff_days <= 30:\n",
    "        return \"un mes\"\n",
    "    elif diff_days <= 90:\n",
    "        return \"3 meses\"\n",
    "    elif diff_days <= 180:\n",
    "        return \"6 meses\"\n",
    "    elif diff_days <= 365:\n",
    "        return \"1 año\"\n",
    "    elif diff_days <= 5 * 365:\n",
    "        return \"5 años\"\n",
    "    elif diff_days <= 10 * 365:\n",
    "        return \"10 años\"\n",
    "    else:\n",
    "        return \"más de 10 años\"\n",
    "\n",
    "# Aplicar la función\n",
    "df[\"DIF_TIEMPO_REGISTRO_HECHO\"] = df.apply(get_difference_dates_registro_hec, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e1ec76",
   "metadata": {},
   "source": [
    "### Construir una variable que mida la diferencia de sexo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64bf2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dif_sex(row):\n",
    "    if row[\"VIC_SEXO\"] == row[\"AGR_SEXO\"]:\n",
    "        return \"no\"\n",
    "    return \"si\"\n",
    "df[\"DIF_SEXO\"] = df.apply(get_dif_sex, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8899f24a",
   "metadata": {},
   "source": [
    "### Construir variable que mida la diferencia de etnia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9778ccb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dif_sex(row):\n",
    "    if row[\"VIC_GRUPET\"] == row[\"AGR_GRUPET\"]:\n",
    "        return \"si\"\n",
    "    return \"no\"\n",
    "df[\"DIF_GRUPET\"] = df.apply(get_dif_sex, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8843c2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def es_indigena(val):\n",
    "    if val == \"ladinos(as)\": return \"no\"\n",
    "    elif val == \"ignorado\" or val == \"no indica\": return \"ignorado\"\n",
    "    else: return \"si\"\n",
    "df[\"VIC_ES_INDIGENA\"] = df[\"VIC_GRUPET\"].apply(lambda val: es_indigena(val))\n",
    "df[\"AGR_ES_INDIGENA\"] = df[\"AGR_GRUPET\"].apply(lambda val: es_indigena(val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03d7e0a",
   "metadata": {},
   "source": [
    "### Construir variable que mida la diferencia de escolaridad\n",
    "El negativo significa que la victima tiene una mayor escolaridad, mientras que positivo significa que el agresor tiene un mayor grado de escolaridad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624f1df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def diferencia_escolaridad(row):\n",
    "    niveles = {\n",
    "        \"ninguno\": 0,\n",
    "        \"primaria\": 1,\n",
    "        \"basicos\": 2,\n",
    "        \"diversificado\": 3,\n",
    "        \"universidad\": 4\n",
    "    }\n",
    "\n",
    "    agr = row[\"AGR_NIV_ESCOLARIDAD\"]\n",
    "    vic = row[\"VIC_NIV_ESCOLARIDAD\"]\n",
    "\n",
    "    if agr == \"ignorado\" or vic == \"ignorado\":\n",
    "        return \"ignorado\"\n",
    "\n",
    "    nivel_agr = niveles.get(agr.lower())\n",
    "    nivel_vic = niveles.get(vic.lower())\n",
    "\n",
    "    if nivel_agr is None or nivel_vic is None:\n",
    "        return \"nivel inválido\"\n",
    "\n",
    "    return nivel_agr - nivel_vic\n",
    "\n",
    "# Aplicar la función al DataFrame\n",
    "df[\"DIF_ESCOLARIDAD_AGR_VIC\"] = df.apply(diferencia_escolaridad, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd8d959",
   "metadata": {},
   "outputs": [],
   "source": [
    "escolaridad_orden = {\n",
    "    \"ninguno\": 0,\n",
    "    \"primero primaria\": 1,\n",
    "    \"segundo primaria\": 2,\n",
    "    \"tercero primaria\": 3,\n",
    "    \"cuarto primaria\": 4,\n",
    "    \"quinto primaria\": 5,\n",
    "    \"sexto primaria\": 6,\n",
    "    \"primaria grado ignorado\": 1,  # suponemos inicio\n",
    "\n",
    "    \"primero basico\": 7,\n",
    "    \"segundo basico\": 8,\n",
    "    \"tercero basico\": 9,\n",
    "    \"basico grado ignorado\": 7,  # suponemos inicio\n",
    "\n",
    "    \"cuarto diversificado\": 10,\n",
    "    \"quinto diversificado\": 11,\n",
    "    \"sexto diversificado\": 12,\n",
    "    \"diversificado grado ignorado\": 10,  # suponemos inicio\n",
    "\n",
    "    \"primer ano universitario\": 13,\n",
    "    \"segundo ano universitario\": 14,\n",
    "    \"tercer ano universitario\": 15,\n",
    "    \"cuarto ano universitario\": 16,\n",
    "    \"quinto ano universitario\": 17,\n",
    "    \"sexto ano universitario\": 18,\n",
    "    \"septimo ano universitario\": 19,\n",
    "    \"universitario grado ignorado\": 13,  # suponemos inicio\n",
    "\n",
    "    \"ignorado\": None\n",
    "}\n",
    "def diferencia_escolaridad_detallada(row):\n",
    "    escolaridad_orden = {\n",
    "        \"ninguno\": 0,\n",
    "        \"primero primaria\": 1,\n",
    "        \"segundo primaria\": 2,\n",
    "        \"tercero primaria\": 3,\n",
    "        \"cuarto primaria\": 4,\n",
    "        \"quinto primaria\": 5,\n",
    "        \"sexto primaria\": 6,\n",
    "        \"primaria grado ignorado\": 6,\n",
    "\n",
    "        \"primero basico\": 7,\n",
    "        \"segundo basico\": 8,\n",
    "        \"tercero basico\": 9,\n",
    "        \"basico grado ignorado\": 9,\n",
    "\n",
    "        \"cuarto diversificado\": 10,\n",
    "        \"quinto diversificado\": 11,\n",
    "        \"sexto diversificado\": 12,\n",
    "        \"diversificado grado ignorado\": 12,\n",
    "\n",
    "        \"primer ano universitario\": 13,\n",
    "        \"segundo ano universitario\": 14,\n",
    "        \"tercer ano universitario\": 15,\n",
    "        \"cuarto ano universitario\": 16,\n",
    "        \"quinto ano universitario\": 17,\n",
    "        \"sexto ano universitario\": 18,\n",
    "        \"septimo ano universitario\": 19,\n",
    "        \"universitario grado ignorado\": 19,\n",
    "\n",
    "        \"ignorado\": None\n",
    "    }\n",
    "\n",
    "    agr = row[\"AGR_ESCOLARIDAD\"]\n",
    "    vic = row[\"VIC_ESCOLARIDAD\"]\n",
    "\n",
    "    nivel_agr = escolaridad_orden.get(agr.lower())\n",
    "    nivel_vic = escolaridad_orden.get(vic.lower())\n",
    "\n",
    "    if nivel_agr is None or nivel_vic is None:\n",
    "        return \"ignorado\"\n",
    "\n",
    "    return nivel_agr - nivel_vic\n",
    "\n",
    "# Aplicar la función\n",
    "df[\"DIF_ESCOLARIDAD_DETALLADA\"] = df.apply(diferencia_escolaridad_detallada, axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88fcb4f8",
   "metadata": {},
   "source": [
    "### Identificar si gana más o menos la víctima que el agresor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb993f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gana_mas_la_victima(row:pd.Series):\n",
    "    if row['VIC_SALARIO']>row['AGR_SALARIO']:\n",
    "        return 'si'\n",
    "    return 'no'\n",
    "df['GANA_MAS_LA_VICTIMA'] = df.apply(gana_mas_la_victima, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2357c833",
   "metadata": {},
   "source": [
    "## Crear los label encodings para kmodes y LCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79fecb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_types = df.select_dtypes(exclude=[\"number\", \"float64\", \"int64\", np.number]).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577d28b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[category_types] = df[category_types].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3175211",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\diego\\AppData\\Local\\Temp\\ipykernel_17104\\838065732.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_ENC'] = le.fit_transform(df[col])\n",
      "C:\\Users\\diego\\AppData\\Local\\Temp\\ipykernel_17104\\838065732.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_ENC'] = le.fit_transform(df[col])\n",
      "C:\\Users\\diego\\AppData\\Local\\Temp\\ipykernel_17104\\838065732.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_ENC'] = le.fit_transform(df[col])\n",
      "C:\\Users\\diego\\AppData\\Local\\Temp\\ipykernel_17104\\838065732.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_ENC'] = le.fit_transform(df[col])\n",
      "C:\\Users\\diego\\AppData\\Local\\Temp\\ipykernel_17104\\838065732.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_ENC'] = le.fit_transform(df[col])\n",
      "C:\\Users\\diego\\AppData\\Local\\Temp\\ipykernel_17104\\838065732.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_ENC'] = le.fit_transform(df[col])\n",
      "C:\\Users\\diego\\AppData\\Local\\Temp\\ipykernel_17104\\838065732.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_ENC'] = le.fit_transform(df[col])\n",
      "C:\\Users\\diego\\AppData\\Local\\Temp\\ipykernel_17104\\838065732.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_ENC'] = le.fit_transform(df[col])\n",
      "C:\\Users\\diego\\AppData\\Local\\Temp\\ipykernel_17104\\838065732.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_ENC'] = le.fit_transform(df[col])\n",
      "C:\\Users\\diego\\AppData\\Local\\Temp\\ipykernel_17104\\838065732.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_ENC'] = le.fit_transform(df[col])\n",
      "C:\\Users\\diego\\AppData\\Local\\Temp\\ipykernel_17104\\838065732.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_ENC'] = le.fit_transform(df[col])\n",
      "C:\\Users\\diego\\AppData\\Local\\Temp\\ipykernel_17104\\838065732.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_ENC'] = le.fit_transform(df[col])\n",
      "C:\\Users\\diego\\AppData\\Local\\Temp\\ipykernel_17104\\838065732.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_ENC'] = le.fit_transform(df[col])\n",
      "C:\\Users\\diego\\AppData\\Local\\Temp\\ipykernel_17104\\838065732.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_ENC'] = le.fit_transform(df[col])\n",
      "C:\\Users\\diego\\AppData\\Local\\Temp\\ipykernel_17104\\838065732.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_ENC'] = le.fit_transform(df[col])\n",
      "C:\\Users\\diego\\AppData\\Local\\Temp\\ipykernel_17104\\838065732.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_ENC'] = le.fit_transform(df[col])\n",
      "C:\\Users\\diego\\AppData\\Local\\Temp\\ipykernel_17104\\838065732.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_ENC'] = le.fit_transform(df[col])\n",
      "C:\\Users\\diego\\AppData\\Local\\Temp\\ipykernel_17104\\838065732.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_ENC'] = le.fit_transform(df[col])\n",
      "C:\\Users\\diego\\AppData\\Local\\Temp\\ipykernel_17104\\838065732.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_ENC'] = le.fit_transform(df[col])\n",
      "C:\\Users\\diego\\AppData\\Local\\Temp\\ipykernel_17104\\838065732.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_ENC'] = le.fit_transform(df[col])\n",
      "C:\\Users\\diego\\AppData\\Local\\Temp\\ipykernel_17104\\838065732.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_ENC'] = le.fit_transform(df[col])\n",
      "C:\\Users\\diego\\AppData\\Local\\Temp\\ipykernel_17104\\838065732.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_ENC'] = le.fit_transform(df[col])\n",
      "C:\\Users\\diego\\AppData\\Local\\Temp\\ipykernel_17104\\838065732.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_ENC'] = le.fit_transform(df[col])\n",
      "C:\\Users\\diego\\AppData\\Local\\Temp\\ipykernel_17104\\838065732.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_ENC'] = le.fit_transform(df[col])\n",
      "C:\\Users\\diego\\AppData\\Local\\Temp\\ipykernel_17104\\838065732.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_ENC'] = le.fit_transform(df[col])\n",
      "C:\\Users\\diego\\AppData\\Local\\Temp\\ipykernel_17104\\838065732.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_ENC'] = le.fit_transform(df[col])\n",
      "C:\\Users\\diego\\AppData\\Local\\Temp\\ipykernel_17104\\838065732.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_ENC'] = le.fit_transform(df[col])\n",
      "C:\\Users\\diego\\AppData\\Local\\Temp\\ipykernel_17104\\838065732.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_ENC'] = le.fit_transform(df[col])\n",
      "C:\\Users\\diego\\AppData\\Local\\Temp\\ipykernel_17104\\838065732.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_ENC'] = le.fit_transform(df[col])\n",
      "C:\\Users\\diego\\AppData\\Local\\Temp\\ipykernel_17104\\838065732.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_ENC'] = le.fit_transform(df[col])\n",
      "C:\\Users\\diego\\AppData\\Local\\Temp\\ipykernel_17104\\838065732.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_ENC'] = le.fit_transform(df[col])\n",
      "C:\\Users\\diego\\AppData\\Local\\Temp\\ipykernel_17104\\838065732.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_ENC'] = le.fit_transform(df[col])\n",
      "C:\\Users\\diego\\AppData\\Local\\Temp\\ipykernel_17104\\838065732.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_ENC'] = le.fit_transform(df[col])\n",
      "C:\\Users\\diego\\AppData\\Local\\Temp\\ipykernel_17104\\838065732.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_ENC'] = le.fit_transform(df[col])\n",
      "C:\\Users\\diego\\AppData\\Local\\Temp\\ipykernel_17104\\838065732.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_ENC'] = le.fit_transform(df[col])\n",
      "C:\\Users\\diego\\AppData\\Local\\Temp\\ipykernel_17104\\838065732.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_ENC'] = le.fit_transform(df[col])\n",
      "C:\\Users\\diego\\AppData\\Local\\Temp\\ipykernel_17104\\838065732.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_ENC'] = le.fit_transform(df[col])\n",
      "C:\\Users\\diego\\AppData\\Local\\Temp\\ipykernel_17104\\838065732.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_ENC'] = le.fit_transform(df[col])\n",
      "C:\\Users\\diego\\AppData\\Local\\Temp\\ipykernel_17104\\838065732.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_ENC'] = le.fit_transform(df[col])\n",
      "C:\\Users\\diego\\AppData\\Local\\Temp\\ipykernel_17104\\838065732.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_ENC'] = le.fit_transform(df[col])\n",
      "C:\\Users\\diego\\AppData\\Local\\Temp\\ipykernel_17104\\838065732.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_ENC'] = le.fit_transform(df[col])\n",
      "C:\\Users\\diego\\AppData\\Local\\Temp\\ipykernel_17104\\838065732.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_ENC'] = le.fit_transform(df[col])\n",
      "C:\\Users\\diego\\AppData\\Local\\Temp\\ipykernel_17104\\838065732.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_ENC'] = le.fit_transform(df[col])\n",
      "C:\\Users\\diego\\AppData\\Local\\Temp\\ipykernel_17104\\838065732.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_ENC'] = le.fit_transform(df[col])\n",
      "C:\\Users\\diego\\AppData\\Local\\Temp\\ipykernel_17104\\838065732.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_ENC'] = le.fit_transform(df[col])\n",
      "C:\\Users\\diego\\AppData\\Local\\Temp\\ipykernel_17104\\838065732.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_ENC'] = le.fit_transform(df[col])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['./dataset/label_encoders.pkl']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoders = {}\n",
    "for col in category_types:\n",
    "    le = LabelEncoder()\n",
    "    df[f'{col}_ENC'] = le.fit_transform(df[col])\n",
    "    encoders[col] = le\n",
    "joblib.dump(encoders, './dataset/label_encoders.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd84112",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('./dataset/violenciaIntrafamiliarGuatemala2008_2023_v3.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
